import "error.oomph" as error

func starts_with_any(Str s, List[Str] prefixes) -> Str | null:
    foreach prefix of prefixes:
        if s.starts_with(prefix):
            return prefix
    return null

func get_simple_identifier(Str code) -> Str | null:
    let first_chars = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_"
    let continue_chars = first_chars + "1234567890"

    let match = starts_with_any(code, first_chars.split(""))
    if match == null:
        return null

    let result = match.get()
    while true:
        let match = starts_with_any(code.remove_prefix(result), continue_chars.split(""))
        if match == null:
            return result
        result = result + match.get()

func get_identifier(Str code) -> Str | null:
    switch get_simple_identifier(code):
        case Str s:
            let remaining = code.remove_prefix(s)
            if remaining.starts_with("::"):
                # TODO: better error handling for foo::123
                return s + "::" + get_simple_identifier(remaining.remove_prefix("::")).get()
            return s
        case *:
            return null

# TODO: enums for type
export class Token(Str type, Str value, error::Location location):
    meth matches(Str type, Str value) -> Bool:
        return self.type == type and self.value == value

func get_int(Str code) -> Str:
    let all_digits = [for let n = 0; n <= 9; n = n+1: n.to_string()]
    let result = ""

    while true:
        switch starts_with_any(code.remove_prefix(result), all_digits):
            case Str digit:
                result = result + digit
            case null _:
                return result

func extract_string(Str code, Str quotes, error::Location location) -> Str:
    let result = quotes

    while true:
        if code.remove_prefix(result).starts_with(quotes):
            return result + quotes

        # Ignore backslash-escaped quotes, and actually, any backslash-escaped char
        if code.remove_prefix(result).starts_with("\\"):
            result = result + "\\"

        if code == result:
            location.error("string does not terminate")
        result = result + code.remove_prefix(result).split("").first()
        if code == result:
            location.error("string does not terminate")

func get_prefix_spaces(Str string) -> Str:
    let result = 0
    while string.starts_with(" "):
        result = result + 1
        string = string.remove_prefix(" ")
    return " ".repeat(result)

func raw_tokenize(Str code, Str path, Int lineno, Str line_prefix) -> List[Token]:
    assert("\n" not in line_prefix)

    # Make sure that every statement ends with newline
    if not code.ends_with("\n"):
        code = code + "\n"

    let op_list = [
        # Longer ops need to be first, otherwise -> is detected as - and > separate
        "->", "==", "!=", "<=", ">=",
        "<", ">",
        ";", ",", ".", ":",
        "(", ")", "[", "]",
        "+", "-", "*", "/",
        "=", "|", "\n",
    ]
    let keyword_list = [
        "let", "import", "as", "export", "func", "meth", "class", "typedef",
        "switch", "case", "auto", "generic", "new", "return", "pass", "mod", "and", "or", "not", "in",
        "if", "elif", "else", "while", "for", "foreach", "of", "continue", "break",
    ]

    # Adding initial newline helps error when file starts with space (weird corner case)
    let result = [
        new Token("op", "\n", new error::Location(path, lineno, line_prefix, ""))
    ]

    while code != "":
        let id = get_identifier(code)
        let op = starts_with_any(code, op_list)
        let int_value = get_int(code)

        if id != null:
            let token_value = id.get()
            if token_value in keyword_list:
                let token_type = "keyword"
            else:
                token_type = "id"

        elif op != null:
            token_type = "op"
            token_value = op.get()

        elif int_value != "":
            let remaining = code.remove_prefix(int_value)
            if remaining.starts_with("."):
                # this may set digit_after_dot to null
                let digit_after_dot = starts_with_any(
                    remaining.remove_prefix("."), "0123456789".split(""))
            else:
                digit_after_dot = null

            if digit_after_dot == null:
                token_type = "int"
                token_value = int_value
            else:
                token_type = "float"
                token_value = int_value + "." + get_int(remaining.remove_prefix("."))

        elif code.starts_with(" "):
            if result != [] and result.last().matches("op", "\n"):
                # Space after newline: indentation
                let spaces = get_prefix_spaces(code)
                if code.remove_prefix(spaces).starts_with("#") or code.remove_prefix(spaces).starts_with("\n"):
                    # This line doesn't actually contain any code, ignore the indent
                    token_type = "skip"
                    token_value = spaces
                else:
                    token_type = "indent"
                    token_value = spaces
            else:
                # Space to be ignored
                token_type = "skip"
                token_value = " "

        elif code.starts_with("#"):
            token_type = "skip"
            token_value = code.split("\n").first()

        elif code.starts_with("\""):
            let rest_of_line = code.split("\n").first()
            let location = new error::Location(path, lineno, line_prefix, rest_of_line)
            if code.starts_with("\"\"\""):
                token_type = "multiline_string"
                token_value = extract_string(code, "\"\"\"", location)
            else:
                token_type = "oneline_string"
                token_value = extract_string(code.split("\n").first(), "\"", location)

        else:
            new error::Location(path, lineno, line_prefix, code.split("\n").first()).error("invalid syntax")

        if token_type != "skip":
            let location = new error::Location(path, lineno, line_prefix, token_value)

            if token_type == "int" and token_value.starts_with("0") and token_value != "0":
                location.error("leading zeros are not allowed")

            result.push(new Token(token_type, token_value, location))

        lineno = lineno + token_value.count("\n")
        line_prefix = (line_prefix + token_value).split("\n").last()
        code = code.remove_prefix(token_value)

    return result

func flip_paren(Str paren) -> Str:
    if paren == "(":
        return ")"
    if paren == ")":
        return "("
    if paren == "[":
        return "]"
    if paren == "]":
        return "["
    assert(false)

func ignore_whitespace_in_parens(List[Token] tokens) -> List[Token]:
    let result = []
    let paren_stack = []

    foreach token of tokens:
        if token.matches("op", "(") or token.matches("op", "["):
            paren_stack.push(token)
        elif token.matches("op", ")") or token.matches("op", "]"):
            if paren_stack == []:
                token.location.error("no matching '{flip_paren(token.value)}'")

            let popped = paren_stack.pop()
            if popped.value != flip_paren(token.value):
                token.location.error("'{popped.value}' and '{token.value}' don't match")

        if paren_stack == [] or token.value.trim() != "":
            result.push(token)

    if paren_stack != []:
        paren_stack.first().location.error(
            "missing '{flip_paren(paren_stack.first().value)}'"
        )
    return result

func combine_not_in(List[Token] tokens) -> List[Token]:
    let result = []
    for let i = 0; i < tokens.length(); :
        if (
            i+1 < tokens.length()
            and tokens.get(i).matches("keyword", "not")
            and tokens.get(i+1).matches("keyword", "in")
        ):
            let combined = tokens.get(i).location.combine(tokens.get(i+1).location)
            result.push(new Token("keyword", "not in", combined))
            i = i + 2
        else:
            result.push(tokens.get(i))
            i = i + 1
    return result

func skip_newlines(List[Token] tokens):
    while tokens != [] and tokens.last().matches("op", "\n"):
        tokens.pop()

func clean_newlines(List[Token] tokens) -> List[Token]:
    let result = []
    tokens = tokens.reversed()

    skip_newlines(tokens)
    while tokens != []:
        let token = tokens.pop()
        result.push(token)
        if token.matches("op", "\n") or token.type in ["begin_block", "end_block"]:
            skip_newlines(tokens)

    return result

func find_blocks(List[Token] tokens) -> List[Token]:
    let indent_error_msg = "indentation must be a multiple of 4 spaces"
    let indent_level = 0
    let result = []
    tokens = tokens.reversed()

    while tokens != []:
        let head = tokens.reversed().slice(0, 3)
        if (
            head.length() == 3
            and head.get(0).matches("op", ":")
            and head.get(1).matches("op", "\n")
            and head.get(2).type == "indent"
        ):
            indent_level = indent_level + 1
            if head.get(2).value != " ".repeat(4*indent_level):
                head.get(2).location.error(indent_error_msg)
            result.push(new Token("begin_block", ":", head.first().location))
            tokens.pop()
            tokens.pop()
            tokens.pop()
            continue

        result.push(head.first())
        tokens.pop()

        if head.first().matches("op", "\n"):
            if head.length() >= 2 and head.get(1).type == "indent":
                let new_level = (head.get(1).value.length() / 4).round()
                let indent_token = tokens.pop()
                if head.get(1).value != " ".repeat(4*new_level):
                    indent_token.location.error(indent_error_msg)
                if new_level > indent_level:
                    head.get(1).location.error("indent without ':' at end of previous line")
            else:
                new_level = 0

            for ; indent_level > new_level; indent_level = indent_level - 1:
                result.push(new Token("end_block", "", head.first().location))

    return result

export func tokenize(Str code, Str path, Int initial_lineno, Str initial_line_prefix) -> List[Token]:
    return clean_newlines(
        find_blocks(
        clean_newlines(
        combine_not_in(
        ignore_whitespace_in_parens(
        raw_tokenize(code, path, initial_lineno, initial_line_prefix))))))
