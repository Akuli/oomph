import "<stdlib>/path.oomph" as path
import "ast.oomph" as ast
import "location.oomph" as location
import "tokenizer.oomph" as tokenizer
typedef Location = location::Location

# token is e.g. "+" or "as"
typedef PrecedenceItem = ast::Expression | ast::Type | tokenizer::Token

# TODO: shouldn't be needed
func is_mod(ast::Expression expr) -> Bool:
    switch expr:
        case ast::BinaryOperator binop:
            return binop.op == "mod"
        case *:
            return false

func add_string(List[ast::Expression] parts, Str suffix, Location location):
    if parts != []:
        switch parts.last():
            case ast::StringConstant old:
                # String concat can be done at compile time
                parts.pop()
                parts.push(new ast::StringConstant(location, old.value + suffix))
                return
            case *:    # TODO: this sucks
                pass

    parts.push(new ast::StringConstant(location, suffix))

# tokens must be in reverse order
class Parser(List[tokenizer::Token] tokens):
    meth peek() -> tokenizer::Token:
        assert(self.tokens != [])  # TODO: error
        return self.tokens.last()

    meth get_token_by_type(Str type) -> tokenizer::Token:
        self.peek()   # Error if end of file
        let token = self.tokens.pop()
        if token.type != type:
            print("Wrong token type: expected {type}, got {token}")
            assert(false)  # TODO: error
        return token

    meth get_token(Str type, Str value) -> tokenizer::Token:
        if self.peek().value != value:
            if value == "\n":
                self.peek().location.error("should be newline")
            self.peek().location.error("should be '{value}'")
        return self.get_token_by_type(type)

    meth parse_import(Str path_of_this_file, Str stdlib_path) -> ast::Import:
        let import_token = self.get_token("keyword", "import")
        let string = self.get_token_by_type("oneline_string").value
        self.get_token("keyword", "as")
        let name = self.get_token_by_type("id").value
        self.get_token("op", "\n")

        string = string.remove_prefix("\"").remove_suffix("\"")
        assert("\"" not in string)
        assert("\\" not in string)
        assert("\{" not in string)
        assert("\}" not in string)

        if string.starts_with("<stdlib>/"):
            let path = stdlib_path + "/" + string.remove_prefix("<stdlib>/")
        else:
            path = path::parent(path_of_this_file) + "/" + string
        return new ast::Import(import_token.location, path, name)

    # TODO: parse_commasep_... methods are a bit copy/pasta
    meth parse_commasep_expression_in_parens(Str left, Str right) -> List[ast::Expression]:
        self.get_token("op", left)
        let result = []
        if not self.peek().matches("op", right):
            result.push(self.parse_expression(null))
            while self.peek().matches("op", ","):
                self.get_token("op", ",")
                if self.peek().matches("op", right):
                    break
                result.push(self.parse_expression(null))
        self.get_token("op", right)
        return result

    meth parse_commasep_types_and_names_in_parens() -> List[ast::TypeAndName]:
        self.get_token("op", "(")
        let result = []
        if not self.peek().matches("op", ")"):
            result.push(self.parse_type_and_name())
            while self.peek().matches("op", ","):
                self.get_token("op", ",")
                if self.peek().matches("op", ")"):
                    break
                result.push(self.parse_type_and_name())
        self.get_token("op", ")")
        return result

    # Weirdly returns location, can't easily return 2 values yet
    meth parse_one_or_more_commasep_types_in_square_brackets(List[ast::Type] result) -> Location:
        let start = self.get_token("op", "[")
        result.push(self.parse_type())
        while self.peek().matches("op", ","):
            self.get_token("op", ",")
            if self.peek().matches("op", "]"):
                break
            result.push(self.parse_type())
        let end = self.get_token("op", "]")
        return start.location.combine(end.location)

    meth parse_block_of_statements() -> List[ast::Statement]:
        self.get_token("begin_block", ":")
        let result = []
        while self.tokens != [] and not self.peek().matches("end_block", ""):
            result.push_all(self.parse_statement())
        self.get_token("end_block", "")
        return result

    meth parse_block_of_methods() -> List[ast::FuncOrMethodDef]:
        self.get_token("begin_block", ":")
        let result = [
            while self.tokens != [] and not self.peek().matches("end_block", ""):
                self.parse_method()
        ]
        self.get_token("end_block", "")
        return result

    meth parse_block_of_cases() -> List[ast::Case]:
        self.get_token("begin_block", ":")
        let result = [
            while self.tokens != [] and not self.peek().matches("end_block", ""):
                self.parse_case()
        ]
        self.get_token("end_block", "")
        return result

    meth tokenize_and_parse_expression(Str code, Location location) -> ast::Expression:
        let parser = new Parser(tokenizer::tokenize(
            code, location.path, location.lineno, location.line_prefix
        ).reversed())
        let result = parser.parse_expression(null)
        parser.get_token("op", "\n")
        assert(parser.tokens == [])
        return result

    # the location contains all we need to know about the string
    meth do_string_contents(Location string_location) -> ast::Expression:
        let result = []
        let escapes = [
            # TODO: oneline and multiline strings should allow different escapes
            ["\\n", "\n"],
            ["\\t", "\t"],
            ["\\\{", "\{"],
            ["\\\}", "\}"],
            ["\\\"", "\""],
            ["\\\\", "\\"],
        ]

        let location = string_location
        while location.code != "":
            if location.code.starts_with("\\"):
                let found_escape = false  # TODO: this sucks
                foreach pair of escapes:
                    if location.code.starts_with(pair.first()):
                        add_string(result, pair.last(), string_location)
                        location = location.remove_prefix(pair.first())
                        found_escape = true
                        break
                assert(found_escape)
            elif location.code.starts_with("\{"):
                assert("\}" in location.code)
                let code = location.code.split("\}").first().remove_prefix("\{")
                let code_location = new Location(
                    location.path, location.lineno, location.line_prefix + "\{", code
                )
                assert("\n" not in code)  # TODO: reconsider? might be useful in multiline strings
                assert("\{" not in code)
                assert("\}" not in code)
                assert("\\" not in code)
                result.push(self.tokenize_and_parse_expression(code, code_location))
                location = location.remove_prefix("\{").remove_prefix(code).remove_prefix("\}")
            else:
                let char = location.code.split("").first()
                add_string(result, char, string_location)
                location = location.remove_prefix(char)

        if result == []:
            return new ast::StringConstant(string_location, "")
        if result.length() == 1:
            return result.first()
        return new ast::StringFormatJoin(string_location, result)

    meth parse_simple_expression(Str error_message) -> ast::Expression:
        if self.peek().type == "oneline_string":
            let token = self.get_token_by_type("oneline_string")
            let result = self.do_string_contents(
                token.location.remove_prefix("\"").remove_suffix("\""),
            )

        elif self.peek().type == "multiline_string":
            let token = self.get_token_by_type("multiline_string")
            result = self.do_string_contents(
                token.location.remove_prefix("\"\"\"").remove_suffix("\"\"\""),
            )

        elif self.peek().type == "id":
            let token = self.get_token_by_type("id")
            result = new ast::GetVar(token.location, token.value)

        elif self.peek().type == "int":
            let token = self.get_token_by_type("int")
            result = new ast::IntConstant(token.location, token.value.to_int())

        elif self.peek().type == "float":
            let token = self.get_token_by_type("float")
            result = new ast::FloatConstant(token.location, token.value)

        elif self.peek().matches("keyword", "new"):
            let new_keyword = self.get_token("keyword", "new")
            result = new ast::Constructor(new_keyword.location, self.parse_type())

        elif self.peek().matches("op", "("):
            self.get_token("op", "(")
            result = new ast::Parenthesized(self.parse_expression(null))
            self.get_token("op", ")")

        elif self.peek().matches("op", "["):
            let square_bracket = self.get_token("op", "[")
            if (
                self.peek().matches("keyword", "while")
                or self.peek().matches("keyword", "for")
                or self.peek().matches("keyword", "foreach")
            ):
                # list comprehension
                let loop_header = self.parse_loop_header()
                self.get_token("op", ":")
                let value = self.parse_expression(null)
                self.get_token("op", "]")
                result = new ast::ListComprehension(loop_header, value)
            else:
                self.tokens.push(square_bracket)   # oops, didn't mean to pop
                result = new ast::ListLiteral(
                    square_bracket.location,  # TODO: not best possible?
                    self.parse_commasep_expression_in_parens("[", "]")
                )
        else:
            self.peek().location.error(error_message)

        while true:
            if self.peek().matches("op", "("):
                let paren = self.peek()
                result = new ast::Call(
                    ast::locate_expression(result).combine(paren.location),
                    result,
                    self.parse_commasep_expression_in_parens("(", ")")
                )
            elif self.peek().matches("op", "."):
                let dot = self.get_token("op", ".")
                let attrib = self.get_token_by_type("id")
                result = new ast::GetAttribute(
                    dot.location.combine(attrib.location),
                    result,
                    attrib.value
                )
            else:
                return result

    # TODO: find_blah_operator() functions should not be as difficult as they are
    meth find_unary_operator(List[PrecedenceItem] magic_list, List[Str] operators) -> Int | null:
        for let i = 0; i < magic_list.length() - 1; i = i+1:
            switch magic_list.get(i):
                case tokenizer::Token operator:
                    if operator.value not in operators:
                        continue
                case *:
                    continue
            switch magic_list.get(i+1):
                case ast::Expression expr:
                    pass
                case *:
                    continue
            return i
        return null

    meth find_binary_operator(List[PrecedenceItem] magic_list, List[Str] operators) -> Int | null:
        for let i = 1; i <= magic_list.length() - 2; i = i+1:
            switch magic_list.get(i-1):
                case ast::Expression expr:
                    pass
                case *:
                    continue
            switch magic_list.get(i):
                case tokenizer::Token operator:
                    if operator.value not in operators:
                        continue
                case *:
                    continue
            switch magic_list.get(i+1):
                case ast::Expression expr:
                    pass
                case *:
                    continue
            return i
        return null

    meth eliminate_operators(List[PrecedenceItem] magic_list, List[Str] unary, List[Str] binary, Str how2chain):
        while magic_list.length() >= 2:
            let un_or_null = self.find_unary_operator(magic_list, unary)
            let bin_or_null = self.find_binary_operator(magic_list, binary)

            if un_or_null != null and bin_or_null != null:
                # Prefer binary operator if both are found in same place (needed for x - y)
                if (un_or_null as not null) < (bin_or_null as not null):
                    bin_or_null = null
                else:
                    un_or_null = null

            if un_or_null != null:
                let i = un_or_null as not null
                let op_and_expr = magic_list.delete_slice(i, i+2)
                let op = op_and_expr.first() as tokenizer::Token
                let expr = op_and_expr.last() as ast::Expression
                magic_list.insert(i, new ast::UnaryOperator(op.location, op.value, expr))
            elif bin_or_null != null:
                let i = bin_or_null as not null
                let lhs_op_rhs = magic_list.delete_slice(i-1, i+2)
                let lhs = lhs_op_rhs.first() as ast::Expression
                let op = lhs_op_rhs.get(1) as tokenizer::Token
                let rhs = lhs_op_rhs.last() as ast::Expression
                let location = ast::locate_expression(lhs).combine(ast::locate_expression(rhs))

                switch lhs:
                    case ast::BinaryOperator binop:
                        if binop.op in binary:
                            # TODO: enum
                            if how2chain == "same_only":
                                if binop.op != op.value:
                                    location.error(
                                        "'a {binop.op} b {op.value} c' is ambiguous, " +
                                        "please add more parentheses"
                                    )
                            elif how2chain == "bool":
                                location.error(
                                    "'a {binop.op} b {op.value} c' is not supported, " +
                                    "did you mean 'a {binop.op} b and b {binop.op} c'?"
                                )
                            elif how2chain == "no_chaining":
                                location.error(
                                    "'a {binop.op} b {op.value} c' is not supported"
                                )
                            elif how2chain == "chaining_allowed":
                                pass
                            else:
                                assert(false)
                    case *:
                        pass

                if op.value == "==" and is_mod(rhs) and not is_mod(lhs):
                    location.error(
                        "'a == b mod c' is ambiguous, " +
                        "use e.g. 'a == (b mod c)' or '(a mod c) == (b mod c)' instead"
                    )

                magic_list.insert(i-1, new ast::BinaryOperator(op.location, lhs, op.value, rhs))
            else:
                break

    meth eliminate_one_as(List[PrecedenceItem] magic_list) -> Bool:
        for let i = 0; i < magic_list.length(); i = i+1:
            switch magic_list.get(i):
                case tokenizer::Token op:
                    if op.value in ["as", "as not"]:
                        # TODO: improve errors
                        assert(0 <= i-1 and i+1 < magic_list.length())
                        let expr = magic_list.get(i-1) as ast::Expression
                        let type = magic_list.get(i+1) as ast::Type
                        magic_list.delete_slice(i-1, i+2)
                        magic_list.insert(i-1, new ast::As(op.location, expr, type, (op.value == "as not")))
                        return true
                case *:
                    pass

        return false

    meth eliminate_as(List[PrecedenceItem] magic_list):
        while self.eliminate_one_as(magic_list):
            pass

    meth get_unary_operators() -> List[PrecedenceItem]:
        return [
            while self.peek().matches("keyword", "not") or self.peek().matches("op", "-"):
                self.tokens.pop() as PrecedenceItem
        ]

    meth parse_expression(Str | null error_message) -> ast::Expression:
        if error_message == null:
            error_message = "should be an expression"

        let binary_ops = [
            "+", "-", "*", "/",
            "==", "!=", "<", ">", "<=", ">=",
            "mod", "as", "as not", "in", "not in", "and", "or",
        ]

        let magic_list = self.get_unary_operators()
        magic_list.push(self.parse_simple_expression(error_message as not null))
        while self.peek().value in binary_ops:
            let op_token = self.tokens.pop()
            magic_list.push(op_token)
            if op_token.value in ["as", "as not"]:
                magic_list.push(self.parse_type())
            else:
                magic_list.push_all(self.get_unary_operators())
                magic_list.push(self.parse_simple_expression(error_message as not null))

        # FIXME: this nestedness sucks in many ways
        for let i = 1; i < magic_list.length(); i = i+1:
            switch magic_list.get(i-1):
                case tokenizer::Token op1:
                    switch magic_list.get(i):
                        case tokenizer::Token op2:
                            if op1.value in ["+", "-"] and op2.value == "-":
                                op1.location.combine(op2.location).error(
                                    "'{op1.value}{op2.value}' is not supported"
                                )
                        case *:
                            pass
                case *:
                    pass

        self.eliminate_as(magic_list)
        self.eliminate_operators(magic_list, [], ["*", "/"], "chaining_allowed")
        self.eliminate_operators(magic_list, ["-"], ["+", "-"], "chaining_allowed")
        self.eliminate_operators(magic_list, [], ["mod"], "no_chaining")
        self.eliminate_operators(magic_list, [], ["==", "!="], "bool")
        self.eliminate_operators(magic_list, [], ["<", ">", "<=", ">="], "bool")
        self.eliminate_operators(magic_list, [], ["in", "not in"], "bool")
        self.eliminate_operators(magic_list, ["not"], [], "bool")
        self.eliminate_operators(magic_list, [], ["and", "or"], "same_only")

        if magic_list.length() != 1:
            print(magic_list)
            assert(false)
        return magic_list.first() as ast::Expression

    meth parse_oneline_ish_statement() -> ast::Statement:
        if self.peek().matches("keyword", "let"):
            let leet = self.get_token("keyword", "let")
            let varname = self.get_token_by_type("id").value
            self.get_token("op", "=")
            let value = self.parse_expression(null)
            return new ast::Let(leet.location, varname, value)

        if self.peek().matches("keyword", "return"):
            let ret = self.get_token("keyword", "return")
            # This is a weird way to check whether an expression is coming up.
            # It doesn't work in e.g. first line of for loop, but if you think
            # that returning there is a good idea, then wtf lol.
            if self.peek().matches("op", "\n"):
                return new ast::Return(ret.location, null)
            return new ast::Return(ret.location, self.parse_expression(null))

        if self.peek().matches("keyword", "pass"):
            return new ast::Pass(self.get_token("keyword", "pass").location)

        if self.peek().matches("keyword", "continue"):
            return new ast::Continue(self.get_token("keyword", "continue").location)

        if self.peek().matches("keyword", "break"):
            return new ast::Break(self.get_token("keyword", "break").location)

        let expr = self.parse_expression("should be a statement")
        if self.peek().matches("op", "="):
            let equals = self.get_token("op", "=")
            value = self.parse_expression(null)
            switch expr:
                case ast::GetVar getvar:
                    return new ast::SetVar(equals.location, getvar.varname, value)
                case ast::GetAttribute getattr:
                    return new ast::SetAttribute(equals.location, getattr.obj, getattr.attribute, value)
                case *:
                    print("can't assing to {expr}")
                    assert(false)

        return expr as ast::Call

    meth parse_case() -> ast::Case:
        let case_keyword = self.get_token("keyword", "case")
        if self.peek().matches("op", "*"):
            self.get_token("op", "*")
            let type_and_varname = null as ast::TypeAndName | null
        else:
            type_and_varname = self.parse_type_and_name()
        let body = self.parse_block_of_statements()
        return new ast::Case(case_keyword.location, type_and_varname, body)

    meth parse_loop_header() -> ast::LoopHeader:
        if self.peek().matches("keyword", "while"):
            let location = self.get_token("keyword", "while").location
            return new ast::ForLoopHeader(location, [], self.parse_expression(null), [])

        if self.peek().matches("keyword", "for"):
            let location = self.get_token("keyword", "for").location

            if self.peek().matches("op", ";"):
                let init = []
            else:
                init = [self.parse_oneline_ish_statement()]
            self.get_token("op", ";")

            if self.peek().matches("op", ";"):
                let cond = null as ast::Expression | null
            else:
                cond = self.parse_expression(null)
            self.get_token("op", ";")

            if self.peek().matches("begin_block", ":"):
                let incr = []
            else:
                incr = [self.parse_oneline_ish_statement()]

            return new ast::ForLoopHeader(location, init, cond, incr)

        if self.peek().matches("keyword", "foreach"):
            let location = self.get_token("keyword", "foreach").location
            let varname = self.get_token_by_type("id").value
            self.get_token("keyword", "of")
            return new ast::ForeachLoopHeader(location, varname, self.parse_expression(null))

        assert(false)

    meth parse_statement() -> List[ast::Statement]:
        if self.peek().matches("keyword", "if"):
            let if_keyword = self.get_token("keyword", "if")
            let condition = self.parse_expression(null)
            let body = self.parse_block_of_statements()
            let ifs = [new ast::ConditionAndBody(if_keyword.location, condition, body)]

            while self.peek().matches("keyword", "elif"):
                let elif_keyword = self.get_token("keyword", "elif")
                let condition = self.parse_expression(null)
                let body = self.parse_block_of_statements()
                ifs.push(new ast::ConditionAndBody(elif_keyword.location, condition, body))

            if self.peek().matches("keyword", "else"):
                self.get_token("keyword", "else")
                let else_body = self.parse_block_of_statements()
            else:
                else_body = []

            return [new ast::If(ifs, else_body) as ast::Statement]

        if (
            self.peek().matches("keyword", "while")
            or self.peek().matches("keyword", "for")
            or self.peek().matches("keyword", "foreach")
        ):
            let header = self.parse_loop_header()
            let body = self.parse_block_of_statements()
            return [new ast::Loop(header, body) as ast::Statement]

        if self.peek().matches("keyword", "switch"):
            let location = self.get_token("keyword", "switch").location
            let union_obj = self.parse_expression(null)
            let cases = self.parse_block_of_cases()
            return [new ast::Switch(location, union_obj, cases) as ast::Statement]

        let result = self.parse_oneline_ish_statement()
        self.get_token("op", "\n")
        return [result]

    meth parse_type_without_unions() -> ast::Type:
        if self.peek().matches("keyword", "auto"):
            return new ast::AutoType(self.get_token("keyword", "auto").location)

        let name_token = self.get_token_by_type("id")
        if self.peek().matches("op", "["):
            let args = []
            let location = self.parse_one_or_more_commasep_types_in_square_brackets(args)
            return new ast::GenericType(location, name_token.value, args)

        return new ast::NamedType(name_token.location, name_token.value)

    meth parse_type() -> ast::Type:
        let first_member = self.parse_type_without_unions()
        if not self.peek().matches("op", "|"):
            return first_member

        let result = [first_member]
        while self.peek().matches("op", "|"):
            self.get_token("op", "|")
            result.push(self.parse_type_without_unions())
        return new ast::UnionType(result)

    meth parse_type_and_name() -> ast::TypeAndName:
        let type = self.parse_type()
        let arg = self.get_token_by_type("id")
        return new ast::TypeAndName(type, arg.value, arg.location)

    meth parse_function_or_method(Location func_or_meth_location) -> ast::FuncOrMethodDef:
        let name = self.get_token_by_type("id").value
        let args = self.parse_commasep_types_and_names_in_parens()

        if self.peek().matches("op", "->"):
            self.get_token("op", "->")
            if self.peek().matches("keyword", "noreturn"):
                # TODO: do something special with noreturn
                let location = self.get_token("keyword", "noreturn").location
                let returntype = new ast::NoReturn(location) as ast::Type | ast::NoReturn | null
            else:
                returntype = self.parse_type()
        else:
            returntype = null

        return new ast::FuncOrMethodDef(
            func_or_meth_location,
            name,
            args,
            returntype,
            self.parse_block_of_statements()
        )

    meth parse_method() -> ast::FuncOrMethodDef:
        return self.parse_function_or_method(self.get_token("keyword", "meth").location)

    meth parse_toplevel() -> ast::ToplevelDeclaration:
        # TODO: don't export everything
        if self.peek().matches("keyword", "export"):
            self.get_token("keyword", "export")

        if self.peek().matches("keyword", "func"):
            return self.parse_function_or_method(self.get_token("keyword", "func").location)

        if self.peek().matches("keyword", "class"):
            let location = self.get_token("keyword", "class").location
            let name = self.get_token_by_type("id").value
            let args = self.parse_commasep_types_and_names_in_parens()
            if self.tokens != [] and self.peek().matches("begin_block", ":"):
                let body = self.parse_block_of_methods()
            else:
                body = []
                self.get_token("op", "\n")
            return new ast::ClassDef(location, name, args, body)

        if self.peek().matches("keyword", "typedef"):
            let location = self.get_token("keyword", "typedef").location
            let name_token = self.get_token_by_type("id")
            if "::" in name_token.value:
                name_token.location.error("typedef name must not contain '::'")
            self.get_token("op", "=")

            let parens = self.peek().matches("op", "(")
            if parens:
                self.get_token("op", "(")
            let type = self.parse_type()
            if parens:
                self.get_token("op", ")")

            self.get_token("op", "\n")
            return new ast::TypeDef(location, name_token.value, type)

        self.peek().location.error("should be function, class, union or typedef")


export func parse_file(
    Str code,
    Str path,
    Str | null stdlib_path,
) -> List[ast::ToplevelDeclaration]:

    let parser = new Parser(tokenizer::tokenize(code, path, 1, "").reversed())
    let result = new List[ast::ToplevelDeclaration]()

    while parser.tokens != [] and parser.peek().matches("keyword", "import"):
        assert(stdlib_path != null)
        result.push(parser.parse_import(path, stdlib_path as not null))
    while parser.tokens != []:
        result.push(parser.parse_toplevel())

    return result
