import "ast.oomph" as ast
import "tokenizer.oomph" as tokenizer

union PrecedenceItem:
    ast::Expression
    Str

# TODO: add a convenient way to do this without util funcs
func get_expr(PrecedenceItem item) -> ast::Expression:
    switch item:
        case ast::Expression expr:
            return expr
        case *:
            assert(false)
func get_op(PrecedenceItem item) -> Str:
    switch item:
        case Str op:
            return op
        case *:
            assert(false)

# TODO: should move to stdlib
func path_parent(Str path) -> Str:
    let parts = path.split("/")
    if parts == []:
        # TODO: this is a bit broken, although python's pathlib is broken in the same way
        return "."
    return parts.slice(0, parts.length() - 1).join("/")

func add_string(List[ast::Expression] parts, Str suffix):
    if parts != []:
        switch parts.last():
            case ast::StringConstant old:
                # String concat can be done at compile time
                parts.pop()
                parts.push(new ast::StringConstant(old.value + suffix))
                return
            case *:    # TODO: this sucks
                pass

    parts.push(new ast::StringConstant(suffix))

# tokens must be in reverse order
class Parser(List[tokenizer::Token] tokens):
    meth peek() -> tokenizer::Token:
        assert(self.tokens != [])  # TODO: error
        return self.tokens.last()

    meth get_token_by_type(Str type) -> tokenizer::Token:
        self.peek()   # Error if end of file
        let token = self.tokens.pop()
        if token.type != type:
            print("Wrong token type: expected {type}, got {token}")
            assert(false)  # TODO: error
        return token

    meth get_token(Str type, Str value) -> tokenizer::Token:
        self.peek()   # Error if end of file
        let token = self.tokens.pop()
        if token.type != type or token.value != value:
            print(self.tokens)
            print("Above is list of tokens.")
            print("Expected type '{type}' and value '{value}', got {token}")
            assert(false)  # TODO: error
        return token

    meth parse_import(Str path_of_this_file, Str stdlib_path) -> ast::Import:
        self.get_token("keyword", "import")
        let string = self.get_token_by_type("oneline_string").value
        self.get_token("keyword", "as")
        let name = self.get_token_by_type("id").value
        self.get_token("op", "\n")

        string = string.remove_prefix("\"").remove_suffix("\"")
        assert(not string.contains("\""))
        assert(not string.contains("\\"))
        assert(not string.contains("\{"))
        assert(not string.contains("\}"))

        if string.starts_with("<stdlib>/"):
            let path = stdlib_path + "/" + string.remove_prefix("<stdlib>/")
        else:
            path = path_parent(path_of_this_file) + "/" + string
        return new ast::Import(path, name)

    # TODO: these are a bit copy/pasta
    meth parse_commasep_expression_in_parens(Str left, Str right) -> List[ast::Expression]:
        self.get_token("op", left)
        let result = []
        if not self.peek().matches("op", right):
            result.push(self.parse_expression())
            while self.peek().matches("op", ","):
                self.get_token("op", ",")
                if self.peek().matches("op", right):
                    break
                result.push(self.parse_expression())
        self.get_token("op", right)
        return result

    meth parse_commasep_types_and_names_in_parens() -> List[ast::TypeAndName]:
        self.get_token("op", "(")
        let result = []
        if not self.peek().matches("op", ")"):
            result.push(self.parse_type_and_name())
            while self.peek().matches("op", ","):
                self.get_token("op", ",")
                if self.peek().matches("op", ")"):
                    break
                result.push(self.parse_type_and_name())
        self.get_token("op", ")")
        return result

    meth parse_block_of_statements() -> List[ast::Statement]:
        self.get_token("begin_block", ":")
        let result = []
        while self.tokens != [] and not self.peek().matches("end_block", ""):
            result.push_all(self.parse_statement())
        self.get_token("end_block", "")
        return result

    meth parse_block_of_methods() -> List[ast::FuncOrMethodDef]:
        self.get_token("begin_block", ":")
        let result = [
            while self.tokens != [] and not self.peek().matches("end_block", ""):
                self.parse_method()
        ]
        self.get_token("end_block", "")
        return result

    meth parse_block_of_cases() -> List[ast::Case]:
        self.get_token("begin_block", ":")
        let result = [
            while self.tokens != [] and not self.peek().matches("end_block", ""):
                self.parse_case()
        ]
        self.get_token("end_block", "")
        return result

    meth parse_block_of_union_members() -> List[ast::Type]:
        self.get_token("begin_block", ":")
        let result = []
        while self.tokens != [] and not self.peek().matches("end_block", ""):
            result.push(self.parse_type())
            self.get_token("op", "\n")
        self.get_token("end_block", "")
        return result

    meth tokenize_and_parse_expression(Str code) -> ast::Expression:
        let parser = new Parser(tokenizer::tokenize(code).reversed())
        let result = parser.parse_expression()
        parser.get_token("op", "\n")
        assert(parser.tokens == [])
        return result

    meth do_string_contents(Str string) -> ast::Expression:
        let result = []
        let escapes = [
            ["\\n", "\n"],
            ["\\t", "\t"],
            ["\\\{", "\{"],
            ["\\\}", "\}"],
            ["\\\"", "\""],
            ["\\\\", "\\"],
        ]

        while string != "":
            if string.starts_with("\\"):
                let found_escape = false  # TODO: this sucks
                foreach pair of escapes:
                    if string.starts_with(pair.first()):
                        add_string(result, pair.last())
                        string = string.remove_prefix(pair.first())
                        found_escape = true
                        break
                assert(found_escape)
            elif string.starts_with("\{"):
                assert(string.contains("\}"))
                let code = string.split("\}").first().remove_prefix("\{")
                assert(not code.contains("\{"))
                assert(not code.contains("\}"))
                assert(not code.contains("\\"))
                result.push(self.tokenize_and_parse_expression(code))
                string = string.remove_prefix("\{").remove_prefix(code).remove_prefix("\}")
            else:
                let char = string.split("").first()
                add_string(result, char)
                string = string.remove_prefix(char)

        if result == []:
            return new ast::StringConstant("")
        if result.length() == 1:
            return result.first()
        return new ast::StringFormatJoin(result)

    meth parse_simple_expression() -> ast::Expression:
        if self.peek().type == "oneline_string":
            let value = self.get_token_by_type("oneline_string").value
            let result = self.do_string_contents(
                value.remove_prefix("\"").remove_suffix("\""))
        elif self.peek().type == "multiline_string":
            let value = self.get_token_by_type("multiline_string").value
            result = self.do_string_contents(
                value.remove_prefix("\"\"\"").remove_suffix("\"\"\""))
        elif self.peek().type == "id":
            result = new ast::GetVar(self.get_token_by_type("id").value)
        elif self.peek().type == "int":
            result = new ast::IntConstant(self.get_token_by_type("int").value.to_int())
        elif self.peek().type == "float":
            result = new ast::FloatConstant(self.get_token_by_type("float").value)
        elif self.peek().matches("keyword", "new"):
            self.get_token("keyword", "new")
            result = new ast::Constructor(self.parse_type())
        elif self.peek().matches("op", "("):
            self.get_token("op", "(")
            result = self.parse_expression()
            self.get_token("op", ")")
        elif self.peek().matches("op", "["):
            let square_bracket = self.get_token("op", "[")
            if (self.peek().matches("keyword", "while")
                or self.peek().matches("keyword", "for")
                or self.peek().matches("keyword", "foreach")):
                # list comprehension
                let loop_header = self.parse_loop_header()
                self.get_token("op", ":")
                let value = self.parse_expression()
                self.get_token("op", "]")
                result = new ast::ListComprehension(loop_header, value)
            else:
                self.tokens.push(square_bracket)   # oops, didn't mean to pop
                result = new ast::ListLiteral(
                    self.parse_commasep_expression_in_parens("[", "]"))
        else:
            print("All tokens: {self.tokens}")
            print("not a valid expression: {self.peek().value}")
            assert(false)

        while true:
            if self.peek().matches("op", "("):
                result = new ast::Call(
                    result, self.parse_commasep_expression_in_parens("(", ")"))
            elif self.peek().matches("op", "."):
                self.get_token("op", ".")
                result = new ast::GetAttribute(result, self.get_token_by_type("id").value)
            else:
                return result

    # TODO: find_blah_operator() functions should not be as difficult as they are
    meth find_unary_operator(List[PrecedenceItem] magic_list, List[Str] operators) -> Optional[Int]:
        for let i = 0; i < magic_list.length() - 1; i = i+1:
            switch magic_list.get(i):
                case Str op:
                    if op not in operators:
                        continue
                case *:
                    continue
            switch magic_list.get(i+1):
                case ast::Expression expr:
                    pass
                case *:
                    continue
            return i
        return null

    meth find_binary_operator(List[PrecedenceItem] magic_list, List[Str] operators) -> Optional[Int]:
        for let i = 0; i <= magic_list.length() - 3; i = i+1:
            switch magic_list.get(i):
                case ast::Expression expr:
                    pass
                case *:
                    continue
            switch magic_list.get(i+1):
                case Str s:
                    if s not in operators:
                        continue
                case *:
                    continue
            switch magic_list.get(i+2):
                case ast::Expression expr:
                    pass
                case *:
                    continue
            return i
        return null

    # TODO: make sure this errors enough
    meth eliminate_operators(List[PrecedenceItem] magic_list, List[Str] unary, List[Str] binary):
        while magic_list.length() >= 2:
            let un_or_null = self.find_unary_operator(magic_list, unary)
            let bin_or_null = self.find_binary_operator(magic_list, binary)

            if un_or_null != null and bin_or_null != null:
                if un_or_null.get() < bin_or_null.get():
                    bin_or_null = null
                elif un_or_null.get() > bin_or_null.get():
                    un_or_null = null
                else:
                    # TODO: error
                    # TODO: test
                    print("ambiguous operators")
                    assert(false)

            if un_or_null != null:
                let i = un_or_null.get()
                let op_and_expr = magic_list.delete_slice(i, i+2)
                let op = get_op(op_and_expr.first())
                let expr = get_expr(op_and_expr.last())
                magic_list.insert(i, new ast::UnaryOperator(op, expr))
            elif bin_or_null != null:
                let i = bin_or_null.get()
                let lhs_op_rhs = magic_list.delete_slice(i, i+3)
                let lhs = get_expr(lhs_op_rhs.first())
                let op = get_op(lhs_op_rhs.get(1))
                let rhs = get_expr(lhs_op_rhs.last())
                magic_list.insert(i, new ast::BinaryOperator(lhs, op, rhs))
            else:
                break

    meth get_unary_operators() -> List[PrecedenceItem]:
        return [
            while (self.peek().matches("keyword", "not")
                   or self.peek().matches("keyword", "not in")
                   or self.peek().matches("op", "-")):
                new PrecedenceItem(self.tokens.pop().value)
        ]

    meth parse_expression() -> ast::Expression:
        let binary_ops = [
            "+", "-", "*", "/",
            "==", "!=", "<", ">", "<=", ">=",
            "in", "not in", "and", "or", "mod",
        ]

        let magic_list = self.get_unary_operators()
        magic_list.push(self.parse_simple_expression())
        while self.peek().value in binary_ops:
            magic_list.push(self.tokens.pop().value)
            magic_list.push_all(self.get_unary_operators())
            magic_list.push(self.parse_simple_expression())

        self.eliminate_operators(magic_list, [], ["*", "/"])
        self.eliminate_operators(magic_list, ["-"], ["+", "-"])
        self.eliminate_operators(magic_list, [], ["mod"])
        self.eliminate_operators(magic_list, [], ["==", "!="])
        self.eliminate_operators(magic_list, [], ["<", ">", "<=", ">="])
        self.eliminate_operators(magic_list, [], ["in", "not in"])
        self.eliminate_operators(magic_list, ["not"], [])
        self.eliminate_operators(magic_list, [], ["and", "or"])

        assert(magic_list.length() == 1)
        switch magic_list.first():
            case ast::Expression expr:
                return expr
            case *:
                assert(false)

    meth parse_oneline_ish_statement() -> ast::Statement:
        if self.peek().matches("keyword", "let"):
            self.get_token("keyword", "let")
            let varname = self.get_token_by_type("id").value
            self.get_token("op", "=")
            let value = self.parse_expression()
            return new ast::Let(varname, value)

        if self.peek().matches("keyword", "return"):
            self.get_token("keyword", "return")
            # This is a weird way to check whether an expression is coming up.
            # It doesn't work in e.g. first line of for loop, but if you think
            # that returning there is a good idea, then wtf lol.
            if self.peek().matches("op", "\n"):
                return new ast::Return(null)
            return new ast::Return(self.parse_expression())

        if self.peek().matches("keyword", "pass"):
            self.get_token("keyword", "pass")
            return new ast::Pass()

        if self.peek().matches("keyword", "continue"):
            self.get_token("keyword", "continue")
            return new ast::Continue()

        if self.peek().matches("keyword", "break"):
            self.get_token("keyword", "break")
            return new ast::Break()

        let expr = self.parse_expression()
        if self.peek().matches("op", "="):
            self.get_token("op", "=")
            value = self.parse_expression()
            switch expr:
                case ast::GetVar getvar:
                    return new ast::SetVar(getvar.varname, value)
                case ast::GetAttribute getattr:
                    return new ast::SetAttribute(getattr.obj, getattr.attribute, value)
                case *:
                    print("can't assing to {expr}")
                    assert(false)

        switch expr:
            case ast::Call call:
                return call
            case *:
                assert(false)

    meth parse_case() -> ast::Case:
        self.get_token("keyword", "case")
        if self.peek().matches("op", "*"):
            self.get_token("op", "*")
            let type_and_varname = new Optional[ast::TypeAndName](null)
        else:
            type_and_varname = self.parse_type_and_name()
        let body = self.parse_block_of_statements()
        return new ast::Case(type_and_varname, body)

    meth parse_loop_header() -> ast::LoopHeader:
        if self.peek().matches("keyword", "while"):
            self.get_token("keyword", "while")
            return new ast::ForLoopHeader([], self.parse_expression(), [])

        if self.peek().matches("keyword", "for"):
            self.get_token("keyword", "for")

            if self.peek().matches("op", ";"):
                let init = []
            else:
                init = [self.parse_oneline_ish_statement()]
            self.get_token("op", ";")

            if self.peek().matches("op", ";"):
                let cond = new Optional[ast::Expression](null)
            else:
                cond = self.parse_expression()
            self.get_token("op", ";")

            if self.peek().matches("begin_block", ":"):
                let incr = []
            else:
                incr = [self.parse_oneline_ish_statement()]

            return new ast::ForLoopHeader(init, cond, incr)

        if self.peek().matches("keyword", "foreach"):
            self.get_token("keyword", "foreach")
            let varname = self.get_token_by_type("id").value
            self.get_token("keyword", "of")
            return new ast::ForeachLoopHeader(varname, self.parse_expression())

        assert(false)

    meth parse_statement() -> List[ast::Statement]:
        if self.peek().matches("keyword", "if"):
            self.get_token("keyword", "if")
            let condition = self.parse_expression()
            let body = self.parse_block_of_statements()
            let ifs = [new ast::ConditionAndBody(condition, body)]

            while self.peek().matches("keyword", "elif"):
                self.get_token("keyword", "elif")
                let condition = self.parse_expression()
                let body = self.parse_block_of_statements()
                ifs.push(new ast::ConditionAndBody(condition, body))

            if self.peek().matches("keyword", "else"):
                self.get_token("keyword", "else")
                let else_body = self.parse_block_of_statements()
            else:
                else_body = []

            return [new ast::Statement(new ast::If(ifs, else_body))]

        if (self.peek().matches("keyword", "while")
            or self.peek().matches("keyword", "for")
            or self.peek().matches("keyword", "foreach")):
            let header = self.parse_loop_header()
            let body = self.parse_block_of_statements()
            return [new ast::Statement(new ast::Loop(header, body))]

        if self.peek().matches("keyword", "switch"):
            self.get_token("keyword", "switch")
            let union_obj = self.parse_expression()
            let cases = self.parse_block_of_cases()
            return [new ast::Statement(new ast::Switch(union_obj, cases))]

        let result = self.parse_oneline_ish_statement()
        self.get_token("op", "\n")
        return [result]

    meth parse_type() -> ast::Type:
        if self.peek().matches("keyword", "auto"):
            self.get_token("keyword", "auto")
            let name = "auto"
        else:
            name = self.get_token_by_type("id").value

        if self.peek().matches("op", "["):
            self.get_token("op", "[")
            let generic_arg = new Optional[ast::Type](self.parse_type())
            self.get_token("op", "]")
        else:
            generic_arg = null

        return new ast::Type(name, generic_arg)

    meth parse_type_and_name() -> ast::TypeAndName:
        let type = self.parse_type()
        let arg = self.get_token_by_type("id").value
        return new ast::TypeAndName(type, arg)

    meth parse_function_or_method() -> ast::FuncOrMethodDef:
        let name = self.get_token_by_type("id").value
        let args = self.parse_commasep_types_and_names_in_parens()

        if self.peek().matches("op", "->"):
            self.get_token("op", "->")
            let returntype = new Optional[ast::Type](self.parse_type())
        else:
            returntype = null

        return new ast::FuncOrMethodDef(
            name, args, returntype, self.parse_block_of_statements())

    meth parse_method() -> ast::FuncOrMethodDef:
        self.get_token("keyword", "meth")
        return self.parse_function_or_method()

    meth parse_toplevel() -> ast::ToplevelDeclaration:
        # TODO: don't export everything
        if self.peek().matches("keyword", "export"):
            self.get_token("keyword", "export")

        if self.peek().matches("keyword", "func"):
            self.get_token("keyword", "func")
            return self.parse_function_or_method()

        if self.peek().matches("keyword", "class"):
            self.get_token("keyword", "class")
            let name = self.get_token_by_type("id").value
            let args = self.parse_commasep_types_and_names_in_parens()
            if self.tokens != [] and self.peek().matches("begin_block", ":"):
                let body = self.parse_block_of_methods()
            else:
                body = []
                self.get_token("op", "\n")
            return new ast::ClassDef(name, args, body)

        if self.peek().matches("keyword", "union"):
            self.get_token("keyword", "union")
            let name = self.get_token_by_type("id").value
            let types = self.parse_block_of_union_members()
            return new ast::UnionDef(name, types)

        print("don't know what to do: {self.peek()}")
        assert(false)


export func parse_file(
    Str code,
    Optional[Str] path,
    Optional[Str] stdlib_path,
) -> List[ast::ToplevelDeclaration]:

    let parser = new Parser(tokenizer::tokenize(code).reversed())
    let result = new List[ast::ToplevelDeclaration]()

    while parser.tokens != [] and parser.peek().matches("keyword", "import"):
        assert(path != null)
        assert(stdlib_path != null)
        result.push(parser.parse_import(path.get(), stdlib_path.get()))
    while parser.tokens != []:
        result.push(parser.parse_toplevel())

    return result
