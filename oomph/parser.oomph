import "tokenizer.oomph" as tokenizer
import "ast.oomph" as ast

# tokens must be in reverse order
class Parser(List[tokenizer::Token] tokens):
    meth peek() -> tokenizer::Token:
        assert(self.tokens.length() != 0)  # TODO: error
        return self.tokens.last()

    # Use when end of file might occur
    meth peek_carefully() -> optional[tokenizer::Token]:
        if self.tokens.length() == 0:
            return null[tokenizer::Token]
        return new optional[tokenizer::Token](self.peek())

    meth get_token_by_type(Str type) -> tokenizer::Token:
        self.peek()   # Error if end of file
        let token = self.tokens.pop()
        if token.type != type:
            # TODO: error
            print("Wrong token type: expected {type}, got {token.type}")
            assert(token.type == type)  # TODO: error
        return token

    meth get_token(Str type, Str value) -> tokenizer::Token:
        let token = self.get_token_by_type(type)
        assert(token.value == value)  # TODO: error
        return token

    meth parse_expression() -> ast::Expression:
        if self.peek().type == "string":
            let string = self.get_token_by_type("string").value
            assert(string.starts_with("\""))
            assert(string.ends_with("\""))
            let result = new ast::Expression(new ast::StringConstant(string.slice(1, string.length() - 1)))
        elif self.peek().type == "id":
            result = new ast::Expression(new ast::GetVar(self.get_token_by_type("id").value))
        elif self.peek().type == "int":
            result = new ast::Expression(new ast::IntConstant(self.get_token_by_type("int").value.to_int()))
        elif self.peek().type == "float":
            result = new ast::Expression(new ast::FloatConstant(self.get_token_by_type("float").value))
        else:
            print("Don't know what to do: {self.peek()}")
            assert(false)

        while self.peek_carefully() != null[tokenizer::Token] and self.peek_carefully().get().matches("op", "("):
            self.get_token("op", "(")
            let args = new List[ast::Expression]()
            if not self.peek().matches("op", ")"):
                args.push(self.parse_expression())
                while self.peek().matches("op", ","):
                    self.get_token("op", ",")
                    args.push(self.parse_expression())
            self.get_token("op", ")")
            result = new ast::Expression(new ast::Call(result, args))

        return result

    meth parse_statement() -> ast::Call:
        let expr = self.parse_expression()
        switch expr:
            case ast::Call:
                self.get_token("op", "\n")
                return expr
            case ast::FloatConstant:
                assert(false)  # TODO: error
            case ast::GetVar:
                assert(false)  # TODO: error
            case ast::StringConstant:
                assert(false)  # TODO: error
            case ast::IntConstant:
                assert(false)  # TODO: error

    meth parse_block_of_statements() -> List[ast::Call]:
        let result = new List[ast::Call]()
        self.get_token_by_type("begin_block")
        while self.tokens.length() != 0 and self.peek().type != "end_block":
            result.push(self.parse_statement())
        self.get_token_by_type("end_block")
        return result

    meth parse_function() -> ast::FuncDef:
        self.get_token("keyword", "export")
        self.get_token("keyword", "func")
        let name = self.get_token_by_type("id").value
        self.get_token("op", "(")
        self.get_token("op", ")")
        return new ast::FuncDef(name, new List[ast::FuncDefArgument](), null[ast::Type], self.parse_block_of_statements())

export func parse_file(Str code) -> List[ast::FuncDef]:
    let parser = new Parser(tokenizer::tokenize(code).reversed())
    let result = new List[ast::FuncDef]()
    while parser.tokens.length() != 0:
        result.push(parser.parse_function())
    return result
