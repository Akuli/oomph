import "tokenizer.oomph" as tokenizer
import "ast.oomph" as ast

union PrecedenceItem:
    ast::Expression
    Str

# TODO: add a convenient way to do this without util funcs
func get_expr(PrecedenceItem item) -> optional[ast::Expression]:
    switch item:
        case ast::Expression:
            return new optional[ast::Expression](item)
        case Str:
            return null[ast::Expression]

# TODO: more list methods
func delete_slice_from_list(List[PrecedenceItem] list, int start, int end) -> List[PrecedenceItem]:
    let stack = new List[PrecedenceItem]()
    let result = new List[PrecedenceItem]()
    while list.length() > end:
        stack.push(list.pop())
    while list.length() > start:
        result.push(list.pop())
    list.push_all(stack.reversed())
    return result.reversed()

func insert_to_list(List[PrecedenceItem] list, int index, PrecedenceItem item):
    let stack = new List[PrecedenceItem]()
    while list.length() > index:
        stack.push(list.pop())
    list.push(item)
    list.push_all(stack.reversed())

# tokens must be in reverse order
class Parser(List[tokenizer::Token] tokens):
    meth peek() -> tokenizer::Token:
        assert(self.tokens.length() != 0)  # TODO: error
        return self.tokens.last()

    # Use when end of file might occur
    # TODO: replace with self.tokens.length() != 0
    meth peek_carefully() -> optional[tokenizer::Token]:
        if self.tokens.length() == 0:
            return null[tokenizer::Token]
        return new optional[tokenizer::Token](self.peek())

    meth get_token_by_type(Str type) -> tokenizer::Token:
        self.peek()   # Error if end of file
        let token = self.tokens.pop()
        if token.type != type:
            # TODO: error
            print("Wrong token type: expected {type}, got {token.type}")
            assert(token.type == type)  # TODO: error
        return token

    meth get_token(Str type, Str value) -> tokenizer::Token:
        let token = self.get_token_by_type(type)
        if token.value != value:
            # TODO: error
            print("Expected '{value}', got '{token.value}'")
            assert(false)
        return token

    meth parse_simple_expression() -> ast::Expression:
        if self.peek().type == "string":
            let string = self.get_token_by_type("string").value
            assert(string.starts_with("\""))
            assert(string.ends_with("\""))
            let result = new ast::Expression(new ast::StringConstant(string.slice(1, string.length() - 1)))
        elif self.peek().type == "id":
            result = new ast::Expression(new ast::GetVar(self.get_token_by_type("id").value))
        elif self.peek().type == "int":
            result = new ast::Expression(new ast::IntConstant(self.get_token_by_type("int").value.to_int()))
        elif self.peek().type == "float":
            result = new ast::Expression(new ast::FloatConstant(self.get_token_by_type("float").value))
        else:
            print("Don't know what to do: {self.peek()}")
            assert(false)

        while self.peek_carefully() != null[tokenizer::Token] and self.peek_carefully().get().matches("op", "("):
            self.get_token("op", "(")
            let args = new List[ast::Expression]()
            if not self.peek().matches("op", ")"):
                args.push(self.parse_expression())
                while self.peek().matches("op", ","):
                    self.get_token("op", ",")
                    args.push(self.parse_expression())
            self.get_token("op", ")")
            result = new ast::Expression(new ast::Call(result, args))

        return result

    meth parse_expression() -> ast::Expression:
        let magic_list = new List[PrecedenceItem]()
        magic_list.push(new PrecedenceItem(self.parse_simple_expression()))
        while self.peek_carefully() != null[tokenizer::Token] and self.peek().matches("op", "+"):
            magic_list.push(new PrecedenceItem(self.get_token_by_type("op").value))
            magic_list.push(new PrecedenceItem(self.parse_simple_expression()))

        while magic_list.length() > 1:
            for let i = 0; i <= magic_list.length() - 3; i = i+1:
                let value = magic_list.get(i+1)
                switch value:
                    case Str:
                        if value != "+":
                            continue
                    case ast::Expression:
                        continue

                # TODO: unpacking
                let lhs_op_rhs = delete_slice_from_list(magic_list, i, i+3)
                let lhs = get_expr(lhs_op_rhs.first()).get()
                let rhs = get_expr(lhs_op_rhs.last()).get()
                insert_to_list(magic_list, i, new PrecedenceItem(new ast::Expression(new ast::BinaryOperator(lhs, "+", rhs))))
                break  # keep going with while loop (TODO: named continue?)

        assert(magic_list.length() == 1)
        let result = magic_list.first()
        switch result:
            case ast::Expression:
                return result
            case Str:
                assert(false)

    meth parse_statement() -> ast::Call:
        let expr = self.parse_expression()
        switch expr:
            case ast::Call:
                self.get_token("op", "\n")
                return expr
            case ast::BinaryOperator:
                assert(false)  # TODO: error
            case ast::FloatConstant:
                assert(false)  # TODO: error
            case ast::GetVar:
                assert(false)  # TODO: error
            case ast::StringConstant:
                assert(false)  # TODO: error
            case ast::IntConstant:
                assert(false)  # TODO: error

    meth parse_block_of_statements() -> List[ast::Call]:
        let result = new List[ast::Call]()
        self.get_token_by_type("begin_block")
        while self.tokens.length() != 0 and self.peek().type != "end_block":
            result.push(self.parse_statement())
        self.get_token_by_type("end_block")
        return result

    meth parse_function() -> ast::FuncDef:
        self.get_token("keyword", "export")
        self.get_token("keyword", "func")
        let name = self.get_token_by_type("id").value
        self.get_token("op", "(")
        self.get_token("op", ")")
        return new ast::FuncDef(name, new List[ast::FuncDefArgument](), null[ast::Type], self.parse_block_of_statements())

export func parse_file(Str code) -> List[ast::FuncDef]:
    let parser = new Parser(tokenizer::tokenize(code).reversed())
    let result = new List[ast::FuncDef]()
    while parser.tokens.length() != 0:
        result.push(parser.parse_function())
    return result
